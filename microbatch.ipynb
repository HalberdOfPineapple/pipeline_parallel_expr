{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Manipulation of micro-batches.\"\"\"\n",
    "import typing\n",
    "from typing import Callable, Iterable, Iterator, List, Tuple, Union, cast\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.cuda.comm\n",
    "\n",
    "__all__: List[str] = []\n",
    "\n",
    "\n",
    "Tensors = Tuple[Tensor, ...]\n",
    "TensorOrTensors = Union[Tensor, Tensors]\n",
    "Function = Callable[[TensorOrTensors], TensorOrTensors]\n",
    "\n",
    "\n",
    "class Batch:\n",
    "    \"\"\"An abstraction of an atomic tensor or a tuple of tensors. This\n",
    "    eliminates every boilerplate code to classify an atomic tensor or a tuple\n",
    "    of tensors.\n",
    "    ::\n",
    "\n",
    "        x = generate_tensor_or_tensors()\n",
    "        x = Batch(x)\n",
    "\n",
    "        # in-place update\n",
    "        x[0] = F.apply(x[0])\n",
    "        x[:] = F.apply(*x)\n",
    "\n",
    "        # f(x) if x is a tensor.\n",
    "        # f(*x) if x is a tuple of tensors.\n",
    "        # y is also a batch.\n",
    "        y = x.call(f)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, value: TensorOrTensors) -> None:\n",
    "        self.value = value\n",
    "        self.atomic = torch.is_tensor(value)\n",
    "\n",
    "    @property\n",
    "    def tensor(self) -> Tensor:\n",
    "        \"\"\"Retrieves the underlying tensor.\"\"\"\n",
    "        if not self.atomic:\n",
    "            raise AttributeError('not atomic batch')\n",
    "        return cast(Tensor, self.value)\n",
    "\n",
    "    @property\n",
    "    def tensors(self) -> Tensors:\n",
    "        \"\"\"Retrieves the underlying tensors.\"\"\"\n",
    "        if self.atomic:\n",
    "            raise AttributeError('batch is atomic')\n",
    "        return cast(Tensors, self.value)\n",
    "\n",
    "    @property\n",
    "    def tensor_or_tensors(self) -> TensorOrTensors:\n",
    "        \"\"\"Retrieves the underlying tensor or tensors regardless of type.\"\"\"\n",
    "        return self.value\n",
    "\n",
    "    def call(self, function: Function) -> 'Batch':\n",
    "        \"\"\"Calls a function by the underlying tensor or tensors. It also wraps\n",
    "        the output with :class:`Batch`.\n",
    "        \"\"\"\n",
    "        return Batch(function(self.value))\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'Batch[atomic={self.atomic!r}]({self.value!r})'\n",
    "\n",
    "    def __iter__(self) -> Iterator[Tensor]:\n",
    "        if self.atomic:\n",
    "            yield self.tensor\n",
    "        else:\n",
    "            yield from self.tensors\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return 1 if self.atomic else len(self.tensors)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tensor:\n",
    "        if not self.atomic:\n",
    "            return self.tensors[index]\n",
    "\n",
    "        if index != 0:\n",
    "            raise IndexError('atomic batch allows index 0 only')\n",
    "\n",
    "        return self.tensor\n",
    "\n",
    "    # NOTE(sublee): pyflakes can't detect \"overload\" instead of \"typing.overload\".\n",
    "    @typing.overload\n",
    "    def __setitem__(self, index: int, value: Tensor) -> None: ...\n",
    "\n",
    "    @typing.overload\n",
    "    def __setitem__(self, index: slice, value: Tensors) -> None: ...\n",
    "\n",
    "    def __setitem__(self, index: Union[int, slice], value: TensorOrTensors) -> None:\n",
    "        if isinstance(index, int):\n",
    "            value = cast(Tensor, value)\n",
    "            self._setitem_by_index(index, value)\n",
    "        else:\n",
    "            value = cast(Tensors, value)\n",
    "            self._setitem_by_slice(index, value)\n",
    "\n",
    "    def _setitem_by_index(self, index: int, value: Tensor) -> None:\n",
    "        if not self.atomic:\n",
    "            i = index\n",
    "            self.value = self.value[:i] + (value,) + self.value[i+1:]\n",
    "            return\n",
    "\n",
    "        if index != 0:\n",
    "            raise IndexError('atomic batch allows index 0 only')\n",
    "\n",
    "        self.value = value\n",
    "\n",
    "    def _setitem_by_slice(self, index: slice, value: Tensors) -> None:\n",
    "        if not (index.start is index.stop is index.step is None):\n",
    "            raise NotImplementedError('only slice [:] supported')\n",
    "\n",
    "        if not self.atomic:\n",
    "            self.value = value\n",
    "            return\n",
    "\n",
    "        if len(value) != 1:\n",
    "            raise IndexError('atomic batch cannot be replaced with multiple tensors')\n",
    "\n",
    "        self.value = value[0]\n",
    "\n",
    "\n",
    "def check(input: TensorOrTensors) -> None:\n",
    "    \"\"\"Checks whether the input is a tensor or tensors.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: input is not a tensor or tensors.\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(input, tuple):\n",
    "        for x in input:\n",
    "            check(x)\n",
    "        return\n",
    "\n",
    "    if not isinstance(input, Tensor):\n",
    "        raise TypeError(f'expected Tensor, but got {input.__class__.__name__}')\n",
    "\n",
    "\n",
    "def scatter(input: TensorOrTensors, chunks: int) -> List[Batch]:\n",
    "    \"\"\"Splits an input mini-batch into multiple micro-batches.\"\"\"\n",
    "    inputs: Iterable[TensorOrTensors]\n",
    "\n",
    "    if isinstance(input, Tensor):\n",
    "        inputs = input.chunk(chunks)\n",
    "    else:\n",
    "        rotated: List[Tensors] = []\n",
    "\n",
    "        for tensor in input:\n",
    "            tensors = tensor.chunk(chunks)\n",
    "            rotated.append(cast(Tensors, tensors))\n",
    "\n",
    "        inputs = zip(*rotated)\n",
    "\n",
    "    return [Batch(x) for x in inputs]\n",
    "\n",
    "\n",
    "def gather(outputs: List[Batch]) -> TensorOrTensors:\n",
    "    \"\"\"Concatenates output micro-batches into a mini-batch.\"\"\"\n",
    "    output: TensorOrTensors\n",
    "\n",
    "    if outputs[0].atomic:\n",
    "        tensors = tuple(b.tensor for b in outputs)\n",
    "        output = torch.cat(tensors)\n",
    "    else:\n",
    "        rotated = [b.tensors for b in outputs]\n",
    "        output_buf = []\n",
    "\n",
    "        for tensors in zip(*rotated):\n",
    "            output_buf.append(torch.cat(tensors))\n",
    "\n",
    "        output = tuple(output_buf)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuple batch: Batch[atomic=False]((tensor(1), tensor(2)))\n",
      "single batch: Batch[atomic=True](tensor(3))\n"
     ]
    }
   ],
   "source": [
    "tup_tensor = (torch.tensor(1), torch.tensor(2))\n",
    "batch = Batch(tup_tensor)\n",
    "print(f\"tuple batch: {batch}\")\n",
    "\n",
    "single_tensor = torch.tensor(3)\n",
    "single_batch = Batch(single_tensor)\n",
    "print(f\"single batch: {single_batch}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) tensor(2)\n",
      "(tensor(1), tensor(2))\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "--------------------\n",
      "tensor(3)\n",
      "(tensor(3),)\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "def print_star(*args):\n",
    "    print(*args)\n",
    "    print(args)\n",
    "    print(type(args))\n",
    "    print(type(args[0]))\n",
    "    print('-' * 20)\n",
    "print_star(*batch)\n",
    "print_star(*single_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "for tensor in single_batch:\n",
    "    print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_batch[0]\n",
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_ddp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
